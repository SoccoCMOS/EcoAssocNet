[DEFAULT]

[HSM]
exposure=True 
; Whether to fit a habitat suitability model
use_covariates=True 
; Set to False if homogeneous environment will fit only the intercept
intercept=False 
; Set to true if an intercept is to be fitted for the HSM component 
fixedoccur=False 
; Set to true if no hsm is fit but instead habitat suitability scores are given. Is ignored if exposure=False
w_sigma2=1.0 
; Variance of weights 
archi_desc_file=../examples/Aravo/config/hsm_archi.json  ###Make sure it is accessible from where your script is
archi_plot_file=../examples/Aravo/archi.png  ###Make sur it is accessible from where your script is
plot=False

[ABUNDANCES]
; Abundance model
bias=True 
; Set to true if a bias is used in the case of empty biotic contexts
offset=False 
; Set to true if this bias if fixed
dist=negbin 
; Probability distribution of used data

[ASSOCIATIONS]
;Association plasticity
assoc_plasticity=False 
; Set to true if a betassoc model needs to be fit

[EMBEDDINGS]
;Embeddings 
k=4 
; dimension
use_reg=True 
;Set to true if we want regularization to be applied to the learnt embeddings
ar_sigma2=1.0 
; Variance of embeddings 
prior=lasso
lambda_lasso=0.1
use_penalty=False 
;Unused for now
emb_initializer=uniform 
fixed_rho=False 
;Set to true if the response embeddings are not fitted Associations are determined by source effects only.

[TRAINING]
;Training parameters
optim=sgd  
;optimizer used amongst supported Tensorflow optimizers See: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers
sample_ratio=0.2 
use_valid=True 
;Set to true if during training a subsample of the data is to be kept apart for validation

LR=0.01 
;Learning rate
use_decay=False   
;Whether to use learning rate decay as a function of the validation loss
lr_update_step=10000 
;Frequency of updates
lr_update_scale=0.5 
;Scale of updates

;Training duration
batch_size=1 
;Batch size Online stochastic gradient descent used batches with single observation (single community)
max_iter=5000 
;Maximum number of iterations = data_size/batch_size * number of epochs (full evaluation of the training set)
nprint=1000 
;Number of batches prediction until a score is printed (if verbose=1), also until a validation is done
